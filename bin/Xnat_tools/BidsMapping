#!/usr/bin/env python

'''
Create/Upload BIDS datatype/tasktype mapping.

Created on October, 2019

@author: Praitayini Kanakaraj, Electrical Engineering, Vanderbilt University
'''
import os
import re
import csv
import sys
import json
import logging
import argparse
from dax import XnatUtils
from datetime import datetime

UNSPECIFIED = object()
def add_parser_args():
    """
    The arguments for the tool
    :return:
    """
    argp = argparse.ArgumentParser(description='details', usage='use "%(prog)s --help" for more information',
                                   formatter_class=argparse.RawTextHelpFormatter)
    argp.add_argument('--host', dest='host', default=None,
                      help='Host for XNAT. Default: using $XNAT_HOST.')
    argp.add_argument('-u', '--username', dest='username', default=None,
                      help='Username for XNAT. Default: using $XNAT_USER.')
    argp.add_argument("-o", "--logfile", dest="logfile", default=None,
                      help="Write the display/output in a file given to this OPTIONS.")
    argp.add_argument('--project', dest="project", default=None,
                      help='Project to create/update BIDS mapping file')
    argp.add_argument('--type', dest="type", default=None,
                      help='The type of mapping either datatype, tasktype or repetition_time_sec')
    argp.add_argument('--create', dest="create", action=None,
                      help='Create the given BIDS new mapping file at project level. (EG. --create <mappingfile>.csv)\n'
                           'Default create creates the default mapping at project file. (EG. --create)\n'
                           'csvfile EG:\n'
                           'scan_type,datatype\n'
                           'T1W/3D/TFE,anat\n'
                           'Resting State,func\n')
    argp.add_argument('--create_default', dest="create_default", action='store_true',
                      help='Default create creates the default mapping at project file. (EG. --create_default)')
    argp.add_argument('--update', dest="update", default=None,
                      help='Update the existing BIDS mapping file at project level. (EG. --update <mappingfile>.csv)'
                           'This option can only add rules')
    argp.add_argument('--replace', dest="replace",  default=None,
                      help='Replace the existing BIDS mapping file at project level. (EG. --replace <mappingfile>.csv)'
                           'This option can remove and add new rules')
    argp.add_argument('--revert', dest="revert", default=None,
                      help='Revert to an old mapping from a specific date/time. (EG: --revert 10-17-19-21:32:15'
                           'or --revert 10-17-19). Check the LOGFILE at project level for the date')
    argp.add_argument('--download', dest="download",  action=None,
                      help='Downloads the current BIDS mapping file (EG: --download <foldername>)')
    argp.add_argument('--template', dest="template",  default=None,
                      help='Default mapping template')

    return argp

def setup_info_logger(name, logfile):
    """
    Using logger for the executables output.
     Setting the information for the logger.

    :param name: Name of the logger
    :param logfile: log file path to write outputs
    :return: logging object
    """
    if logfile:
        handler = logging.FileHandler(logfile, 'w')
    else:
        handler = logging.StreamHandler()

    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    logger.addHandler(handler)
    return logger

def template():
    """
    Function to generate the scan type from a project
    in csv
    :return:
    """
    #TODO sd | default mapping | rule at project level
    sd_list = []
    template_dir = OPTIONS.template
    scans_list_global = XNAT.get_project_scans(project)
    for sd in scans_list_global:
        sd_list.append(sd['scan_type'])
    sd_set = set(sd_list)
    uniq_sd = filter(None, list(sd_set))
    with open(template_dir, "w+") as f:
        wr = csv.writer(f)
        for row in uniq_sd:
            wr.writerow([row])
    LOGGER.info('Template with scan_type at %s', template_dir)

def default():
    """
    Function to make the default mapping at project level if
    mapping does not exit
    #TODO go back to default when wanted? use findchange for logging??
    :return:
    """
    new_mapping = dict()
    new_mapping[project] = {}
    if mapping_type == 'repetition_time_sec':
        LOGGER.info('Repetition time does not have default mapping, use --create')
    else:
        if mapping_type == 'datatype':
            scans_list_global = XNAT.get_project_scans('LANDMAN')

            for sd in scans_list_global:
                c = re.search('T1|T2|T1W', sd['scan_type'])
                if not c == None:
                    sd_anat = sd['scan_type']
                    new_mapping[project][sd_anat] = "anat"

            for sd in scans_list_global:
                c = re.search('rest|Resting state', sd['scan_type'], flags=re.IGNORECASE)
                if not c == None:
                    sd_func = sd['scan_type']
                    new_mapping[project][sd_func] = "func"

            for sd in scans_list_global:
                c = re.search('dwi|dti', sd['scan_type'], flags=re.IGNORECASE)
                if not c == None:
                    sd_dwi = sd['scan_type']
                    new_mapping[project][sd_dwi] = "dwi"

            for sd in scans_list_global:
                c = re.search('Field|B0', sd['scan_type'], flags=re.IGNORECASE)
                if not c == None:
                    sd_fmap = sd['scan_type']
                    new_mapping[project][sd_fmap] = "fmap"

        if mapping_type == 'tasktype':
            scans_list_global = XNAT.get_project_scans('LANDMAN')
            for sd in scans_list_global:
                c = re.search('rest', sd['scan_type'], flags=re.IGNORECASE)
                if not c == None:
                    sd_func = sd['scan_type']
                    new_mapping[project][sd_func] = "rest"

        new_json_name = d_m_y + '_' + mapping_type + '.json'
        is_json_present = False
        for res in XNAT.select(res_files).get():
            if not res.endswith('.json'):
                continue
            else:
                is_json_present = True

        if not is_json_present:
            XNAT.select(os.path.join(res_files, new_json_name)).put(src=json.dumps(new_mapping, indent=2))
            log_new_mapping(new_mapping)
            LOGGER.info('CREATED: Default mapping file %s is uploaded' % new_json_name)
        else:
            LOGGER.info('Datatype mapping exists at project level. You can update it using --update to update it '
                        'or --replace to replace the mapping')


def create():
    """
    Function to read the given csv file and create new mapping
    at project level
    :return:
    """
    dir_new_csv = OPTIONS.create
    new_mapping = dict()
    new_mapping[project] = {}
    csv_check(dir_new_csv)
    with open(dir_new_csv) as csvFile:
        csvReader = csv.DictReader(csvFile)
        for rows in csvReader:
            sd = rows['scan_type']
            if mapping_type == 'datatype':
                new_mapping[project][sd] = rows['datatype']
            elif mapping_type == 'tasktype':
                new_mapping[project][sd] = rows['tasktype']
            elif mapping_type == 'repetition_time_sec':
                new_mapping[project][sd] = rows['repetition_time_sec']
    LOGGER.info('date %s' % (date.strftime("%d-%m-%y-%H:%M:%S")))
    new_json_name = d_m_y + '_' + mapping_type + '.json'
    is_json_present = False
    for res in XNAT.select(res_files).get():
        if not res.endswith('.json'):
            continue
        else:
            is_json_present = True

    if not is_json_present:
        XNAT.select(os.path.join(res_files, new_json_name)).put(src=json.dumps(new_mapping, indent=2))
        log_new_mapping(new_mapping)
        LOGGER.info('CREATED: New mapping file %s is uploaded' % new_json_name)
    else:
        LOGGER.info('Mapping exists at project level. You can update it using --update to update it '
                    'or --replace to replace the mapping')


def log_new_mapping(d):
    """
    Logging when new mapping is created fat project level
    :param d: new mapping
    :return:
    """
    for k, v in d[project].iteritems():
        row0 = d_m_y, " + ", k + " : " + v
        CSVWRITER.writerow(row0)


def update():
    """
    Function to read the csv file with new rules and to add new rules
    at project level
    :return:
    """
    new_json_name = d_m_y + '_' + mapping_type + '.json'
    if OPTIONS.update:
        src_path = OPTIONS.update
    if OPTIONS.replace:
        src_path = OPTIONS.replace
    new_mapping = dict()
    new_mapping[project] = {}
    csv_check(src_path)
    with open(src_path, 'r') as csvFile:
        csvReader = csv.DictReader(csvFile)
        for rows in csvReader:
            sd = rows['scan_type']
            if mapping_type == 'datatype':
                new_mapping[project][sd] = rows['datatype']
            elif mapping_type == 'tasktype':
                new_mapping[project][sd] = rows['tasktype']
            elif mapping_type == 'repetition_time_sec':
                new_mapping[project][sd] = rows['repetition_time_sec']
    if len(XNAT.select(res_files).get()) > 1:
        for res in XNAT.select(res_files).get():
            if res.endswith('.json'):
                with open(XNAT.select(os.path.join(res_files, res)).get(dest=os.path.join("/tmp",res)), "r+") as f:
                    prev_mapping = json.load(f)
                    if project in prev_mapping.keys():
                        for k, v in new_mapping.items():
                            if OPTIONS.update:
                                findDiff(new_mapping, prev_mapping)
                                prev_mapping[k].update(v)
                            if OPTIONS.replace:
                                findDiff_change(new_mapping, prev_mapping)
                                prev_mapping = new_mapping

                        XNAT.select(os.path.join(res_files, new_json_name)).put(src=
                                                                                json.dumps(prev_mapping, indent=2),
                                                                                overwrite=True)
                        XNAT.select(os.path.join(res_files, res)).delete()
                        os.remove(os.path.join("/tmp",res))
                        LOGGER.info('UPDATED: uploaded mapping file %s' % new_json_name)
                    else:
                        LOGGER.error('ERROR: The mapping file format should have project as key')
    else:
        LOGGER.error('ERROR: No mapping at project level to update or replace')

def csv_check(src_path):
    with open(src_path, 'r') as csvFile:
        csvReader = csv.DictReader(csvFile)
        if csvReader.fieldnames[0] == "scan_type" and csvReader.fieldnames[1] in \
                ["datatype", "tasktype", "repetition_time_sec"]:
            if csvReader.fieldnames[1] == "datatype":
                for rows in csvReader:
                    if rows['datatype'] not in ["anat", "dwi", "func", "fmap"]:
                        LOGGER.error("ERROR in CSV unknown datatype column. Datatype should be anat, dwi, fmap or func")
                        sys.exit()
                LOGGER.info("CSV mapping format is good")
            else:
                LOGGER.info("CSV mapping format is good")
        else:
            LOGGER.error("ERROR in CSV column headers. Column headers should be datatype, tasktype or repetition_time_sec")
            sys.exit()

def revert():
    """
    Function to go back a mapping of a previous date/time
    using the log file at project level
    :return:
    """
    new_json_name = d_m_y + '_' + mapping_type + '.json'
    orig_mapping = None
    for res in XNAT.select(res_files).get():
        if res.endswith('.json'):
            res_obj = XNAT.select(os.path.join(res_files, res))
            with open(res_obj.get(), "r+") as f:
                prev_mapping = json.load(f)
                f.seek(0, 0)
                orig_mapping = json.load(f)

                with open(XNAT.select(os.path.join(res_files, 'LOGFILE.txt')).get(), "r+") as lf:
                    lines = lf.readlines()
                    lines.reverse()
                    for l in lines:
                        if not l.startswith(OPTIONS.revert):
                            mapping_all = l.split(",")
                            if mapping_all[1].strip() == '+':
                                prev_mapping[project].pop(mapping_all[2].split(':')[0].strip())
                            if mapping_all[1].strip() == '-':
                                prev_mapping[project].update({mapping_all[2].split(':')[0].
                                                             strip(): mapping_all[2].split(':')[1].strip()})
                        else:
                            break
                findDiff_change(prev_mapping, orig_mapping)
            XNAT.select(os.path.join(res_files, new_json_name)).put(src=json.dumps(prev_mapping, indent=2))
            res_obj.delete()
            LOGGER.info('REVERTED: changed mapping file %s' % new_json_name,)


def findDiff(d1, d2, path=""):
    """
    Function to record/log the changing made when adding rules
    :param d1: dict with new mapping
    :param d2: dict with old mapping
    :param path: ""
    :return:
    """
    for k, v in d1.iteritems():
        if k not in d2.keys():
            row1 = d_m_y, " + ", k + " : " + v
            CSVWRITER.writerow(row1)
        else:
            if type(d1[k]) is dict:
                if path == "":
                    path = k
                else:
                    path = path + "->" + k
                findDiff(d1[k], d2[k], path)
            else:
                if d1[k] != d2[k]:
                    row2 = d_m_y, " - ", k + " : " + d2[k]
                    CSVWRITER.writerow(row2)
                    row3 = d_m_y, " + ", k + " : " + d1[k]
                    CSVWRITER.writerow(row3)


def findDiff_change(d1, d2, path=""):
    """
    Function to record/log the changing made when reverting rules
    :param d1: dict with new mapping
    :param d2: dict with previous mapping
    :param path: ""
    :return:
    """
    for d1_k, d1_v in d1.iteritems():
        for k, v in d1[d1_k].iteritems():
            row4 = d_m_y, " + ", k + " : " + v
            CSVWRITER.writerow(row4)
    for d2_k, d2_v in d1.iteritems():
        for k, v in d2[d2_k].iteritems():
            row5 = d_m_y, " - ", k + " : " + v
            CSVWRITER.writerow(row5)




def mapping_download():
    """
    Function to download the mapping file at project level
    :return:
    """
    download_file = OPTIONS.download
    download_dir = os.path.join(os.getcwd(), download_file)
    os.makedirs(download_dir)
    XNAT.select('/projects/' + project + '/resources/BIDS_' + mapping_type + '/').get(
                 dest_dir=download_dir)
    LOGGER.info('DOWNLOADED: %s mapping file at %s' % (mapping_type, download_dir))


if __name__ == '__main__':
    parser = add_parser_args()
    OPTIONS = parser.parse_args()
    if OPTIONS.host:
        HOST = OPTIONS.host
    else:
        HOST = os.environ['XNAT_HOST']
    if OPTIONS.username:
        MSG = "Please provide the password for user <%s> on xnat(%s):"
        PWD = getpass.getpass(prompt=MSG % (OPTIONS.username, HOST))
    else:
        PWD = None
    LOGGER = setup_info_logger('BidsMapping', OPTIONS.logfile)
    MSG = 'INFO: connection to xnat <%s>:' % (HOST)
    LOGGER.info(MSG)
    XNAT = XnatUtils.get_interface(host=OPTIONS.host,
                                 user=OPTIONS.username,
                                 pwd=PWD)
    date = datetime.now()
    d_m_y = date.strftime("%m-%d-%y-%H:%M:%S")

    if not OPTIONS.project:
        LOGGER.info("WARNING: Project is require. Use --project")
    else:
        project = OPTIONS.project
        if OPTIONS.template:
            template()
        else:
            if not OPTIONS.type:
                LOGGER.info("WARNING: Type is required. Use --type")
            elif OPTIONS.type not in ["datatype", "tasktype", "repetition_time_sec"]:
                LOGGER.error("ERROR: Type must be datatype or tasktype or repetition_time_sec")
            else:
                mapping_type = OPTIONS.type
                CSVWRITER = None
                res_files = '/data/projects/' + project + '/resources/BIDS_' + mapping_type + '/files'

                xnat_logfile = XNAT.select(os.path.join(res_files, 'LOGFILE.txt'))
                if not xnat_logfile.exists():
                    if OPTIONS.revert:
                        LOGGER.error('Cannot perform --revert. Create mapping with --create option first')
                        sys.exit()
                    xnat_logfile.put(src="Logfile\n")
                LOGFILE = xnat_logfile.get()
                csvfilewrite = open(LOGFILE, 'ab')
                CSVWRITER = csv.writer(csvfilewrite, delimiter=',')
                if OPTIONS.create:
                    create()
                if OPTIONS.create_default:
                    default()
                if OPTIONS.update or OPTIONS.replace:
                    update()
                if OPTIONS.revert:
                    revert()
                if OPTIONS.download:
                    mapping_download()

                csvfilewrite.close()
                XNAT.select(os.path.join(res_files, 'LOGFILE.txt')).put(src=LOGFILE, overwrite=True)











